{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "488c5555-4338-4494-93e9-838974d67974",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-19 15:59:05,951 - INFO - Loading datasets...\n",
      "2025-01-19 15:59:08,677 - INFO - Training teacher model...\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ubuntu/jupyter_env/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_45203/232642667.py:115: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = GradScaler()\n",
      "/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "2025-01-19 15:59:09,226 - INFO - Epoch 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b632f4e1d3d4378a9ce7ddc45b8bb67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45203/232642667.py:129: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2647ba05773c43149f592e92cc5f911b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-19 18:32:08,512 - INFO - Metrics: {'epoch': 1, 'train_loss': 0.5162448072258163, 'val_loss': 0.3262274710656813, 'accuracy': 0.86184, 'f1': 0.8615977149527893, 'learning_rate': 7.820000000000001e-06}\n",
      "2025-01-19 18:32:18,356 - INFO - Epoch 2/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2833653693084f4b9b135f9e693f196f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45203/232642667.py:129: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f11f58e456b4fb4a5c0c73269512849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-19 21:06:18,722 - INFO - Metrics: {'epoch': 2, 'train_loss': 0.2970118322278685, 'val_loss': 0.3012382892767906, 'accuracy': 0.87356, 'f1': 0.8731432015356452, 'learning_rate': 1.5640000000000003e-05}\n",
      "2025-01-19 21:06:50,077 - INFO - Epoch 3/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41bdbf999b354a98b36fdc95d743b78b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45203/232642667.py:129: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b4e0c909554eda930c528bbaff3f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-20 02:51:13,414 - INFO - Metrics: {'epoch': 3, 'train_loss': 0.220952901600972, 'val_loss': 0.27243215005006405, 'accuracy': 0.89084, 'f1': 0.8908355843430524, 'learning_rate': 0.0}\n",
      "2025-01-20 02:51:44,034 - INFO - Training student model...\n",
      "/home/ubuntu/jupyter_env/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_45203/232642667.py:115: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = GradScaler()\n",
      "/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "2025-01-20 02:51:44,436 - INFO - Epoch 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9123678792f40b683157516687f12b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45203/232642667.py:129: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5193d7b005214a2db17ae4a945021431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-20 03:58:40,538 - INFO - Metrics: {'epoch': 1, 'train_loss': 0.6945401575711682, 'val_loss': 0.6919617516457882, 'accuracy': 0.5006, 'f1': 0.3348068834040917, 'learning_rate': 7.820000000000001e-06}\n",
      "2025-01-20 03:58:41,987 - INFO - Epoch 2/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e4ec50fa68490ea34c58776781881b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45203/232642667.py:129: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7316935a8180>Exception ignored in: \n",
      "Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7316935a8180>Exception ignored in:   File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7316935a8180>\n",
      "Traceback (most recent call last):\n",
      "      File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "self._shutdown_workers()\n",
      "    \n",
      "Exception ignored in:   File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "  File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7316935a8180>self._shutdown_workers()    \n",
      "    \n",
      "if w.is_alive():Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "  File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "if w.is_alive():    \n",
      "\n",
      "    if w.is_alive():   self._shutdown_workers()\n",
      " \n",
      "   File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "      if w.is_alive(): ^^ ^ ^ \n",
      "  ^   ^ ^   ^   ^  ^  ^ ^^^^^^^\n",
      "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^    ^^^^^^^^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n",
      "^^^ ^^^^^ ^^ ^\n",
      "^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "^ \n",
      "\n",
      "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      " assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "                         ^   ^ ^^^ ^^^^^ ^^ ^^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^AssertionError: can only test a child process^^^\n",
      "AssertionError: can only test a child process\n",
      "^\n",
      "^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process^^\n",
      "^^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ec79bfb90c43aca3bf28e99453bc06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-20 05:06:42,617 - INFO - Metrics: {'epoch': 2, 'train_loss': 0.6752846569508848, 'val_loss': 0.5729781811118431, 'accuracy': 0.70224, 'f1': 0.7013948758333788, 'learning_rate': 1.5640000000000003e-05}\n",
      "2025-01-20 05:06:43,849 - INFO - Epoch 3/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b5408e888c40e9aac9805828f98bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45203/232642667.py:129: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7316935a8180>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7316935a8180>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7316935a8180>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "    ^   ^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7316935a8180>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b7ba0db3f54a71b205d2b7017a6abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-20 06:14:53,802 - INFO - Metrics: {'epoch': 3, 'train_loss': 0.45204234228033546, 'val_loss': 0.435336763282185, 'accuracy': 0.79724, 'f1': 0.7971066159415434, 'learning_rate': 0.0}\n",
      "2025-01-20 06:14:55,086 - INFO - Applying pruning...\n",
      "/home/ubuntu/jupyter_env/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_45203/232642667.py:115: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = GradScaler()\n",
      "/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "2025-01-20 06:14:55,527 - INFO - Epoch 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28754f1e942e44a5868324e61ee070ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45203/232642667.py:129: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7316935a8180>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7316935a8180>\n",
      "Traceback (most recent call last):\n",
      "    if w.is_alive():\n",
      "  File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "         Exception ignored in: self._shutdown_workers()<function _MultiProcessingDataLoaderIter.__del__ at 0x7316935a8180>  \n",
      "^^\n",
      "^^  File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^    ^if w.is_alive():^\n",
      "Traceback (most recent call last):\n",
      "^  File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "  ^    ^self._shutdown_workers() ^\n",
      "^   File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "       File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "if w.is_alive():    assert self._parent_pid == os.getpid(), 'can only test a child process' Exception ignored in: \n",
      "\n",
      "       <function _MultiProcessingDataLoaderIter.__del__ at 0x7316935a8180> \n",
      "  ^^^ ^Traceback (most recent call last):\n",
      "  ^   File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^    ^self._shutdown_workers()^^^^^\n",
      "^  File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^    ^\n",
      "if w.is_alive():  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      " ^     ^   ^         ^^^ ^ ^^ \n",
      "    File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      "^   ^^ ^^^ ^^^^^ ^^^ ^^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^^^    ^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n",
      "^ ^^^^^^^^^^\n",
      " ^AssertionError^^: ^^ can only test a child process^^\n",
      "^^ \n",
      "   AssertionError :   can only test a child process \n",
      "^^^^^^^^^^^^^^^^^^^^^\n",
      "^AssertionError: ^can only test a child process\n",
      "^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ba47e26bf646908fc9f69c1388a3f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-20 07:24:35,256 - INFO - Metrics: {'epoch': 1, 'train_loss': 0.37206131815338683, 'val_loss': 0.43944935735953433, 'accuracy': 0.80208, 'f1': 0.8015950360483053, 'learning_rate': 7.820000000000001e-06}\n",
      "2025-01-20 07:24:56,754 - INFO - Epoch 2/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c618131ff91f4e7f9f5f3d88abc62d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45203/232642667.py:129: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478191b3b6734cdfb05ac90a969624ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-20 08:33:20,380 - INFO - Metrics: {'epoch': 2, 'train_loss': 0.3575733512392282, 'val_loss': 0.4440631276887396, 'accuracy': 0.799, 'f1': 0.7981743551832109, 'learning_rate': 1.5640000000000003e-05}\n",
      "2025-01-20 08:33:20,381 - INFO - Epoch 3/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c222d535eab4b13b440103c9667c98a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45203/232642667.py:129: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7316935a8180>\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7316935a8180>  File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7316935a8180>        self._shutdown_workers()self._shutdown_workers()Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7316935a8180>\n",
      "\n",
      "  File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "          File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "self._shutdown_workers()\n",
      "  File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "        Traceback (most recent call last):\n",
      "if w.is_alive():if w.is_alive():if w.is_alive():\n",
      "\n",
      "\n",
      "        File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "         self._shutdown_workers()   \n",
      "   File \"/home/ubuntu/jupyter_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    ^    ^ if w.is_alive(): ^^^^\n",
      "^^ ^^ ^^ ^  ^^^ ^^^ ^^^^^^^^^\n",
      "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      "^^^^^ ^ ^^ ^^\n",
      "\n",
      "^   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^ ^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^    \n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'     \n",
      " assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'  \n",
      "                          ^  ^^^ ^^  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^AssertionError^: can only test a child process^^\n",
      "\n",
      "AssertionErrorAssertionError: can only test a child process: \n",
      "can only test a child process\n",
      "^\n",
      "^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e552f8fdb44ace81947d674e1051a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-20 09:41:46,217 - INFO - Metrics: {'epoch': 3, 'train_loss': 0.33169591484014943, 'val_loss': 0.43250956128129875, 'accuracy': 0.80532, 'f1': 0.8047632707523465, 'learning_rate': 0.0}\n",
      "2025-01-20 09:42:07,687 - INFO - Quantizing model...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from transformers import (\n",
    "    BertTokenizer, \n",
    "    BertForSequenceClassification,\n",
    "    BertConfig,\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "import wandb\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Dict, Any, List\n",
    "import logging\n",
    "import gc\n",
    "import psutil\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch.nn.utils.prune as prune\n",
    "from dataclasses import asdict\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    level=logging.INFO\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    batch_size: int = 32\n",
    "    accumulation_steps: int = 2\n",
    "    epochs: int = 3\n",
    "    max_length: int = 128  # Reduced from 256\n",
    "    learning_rate: float = 2e-5\n",
    "    warmup_steps: int = 1000\n",
    "    weight_decay: float = 0.01\n",
    "    max_grad_norm: float = 1.0\n",
    "    early_stopping_patience: int = 2\n",
    "    num_workers: int = 4\n",
    "\n",
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, split: str, config: TrainingConfig):\n",
    "        self.dataset = load_dataset('imdb')[split]\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.max_length = config.max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            item['text'],\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(item['label'])\n",
    "        }\n",
    "\n",
    "class EfficientTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        train_loader: DataLoader,\n",
    "        val_loader: DataLoader,\n",
    "        config: TrainingConfig\n",
    "    ):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = model.to(self.device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        \n",
    "        # Initialize optimizer with weight decay\n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                'params': [p for n, p in model.named_parameters() \n",
    "                          if not any(nd in n for nd in no_decay)],\n",
    "                'weight_decay': config.weight_decay\n",
    "            },\n",
    "            {\n",
    "                'params': [p for n, p in model.named_parameters() \n",
    "                          if any(nd in n for nd in no_decay)],\n",
    "                'weight_decay': 0.0\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        self.optimizer = AdamW(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr=config.learning_rate,\n",
    "            eps=1e-8\n",
    "        )\n",
    "        \n",
    "        # Calculate total steps for scheduler\n",
    "        num_update_steps_per_epoch = len(train_loader) // config.accumulation_steps\n",
    "        num_training_steps = num_update_steps_per_epoch * config.epochs\n",
    "        \n",
    "        self.scheduler = get_linear_schedule_with_warmup(\n",
    "            self.optimizer,\n",
    "            num_warmup_steps=config.warmup_steps,\n",
    "            num_training_steps=num_training_steps\n",
    "        )\n",
    "        \n",
    "        self.scaler = GradScaler()\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.patience_counter = 0\n",
    "        \n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        with tqdm(total=len(self.train_loader), desc=\"Training\") as pbar:\n",
    "            for i, batch in enumerate(self.train_loader):\n",
    "                batch = {k: v.to(self.device) for k, v in batch.items()}\n",
    "                \n",
    "                # Automatic mixed precision training\n",
    "                with autocast():\n",
    "                    outputs = self.model(**batch)\n",
    "                    loss = outputs.loss / self.config.accumulation_steps\n",
    "                \n",
    "                # Scale loss and backward pass\n",
    "                self.scaler.scale(loss).backward()\n",
    "                \n",
    "                if (i + 1) % self.config.accumulation_steps == 0:\n",
    "                    # Unscale gradients for clipping\n",
    "                    self.scaler.unscale_(self.optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(\n",
    "                        self.model.parameters(),\n",
    "                        self.config.max_grad_norm\n",
    "                    )\n",
    "                    \n",
    "                    # Optimizer step with scaling\n",
    "                    self.scaler.step(self.optimizer)\n",
    "                    self.scaler.update()\n",
    "                    self.scheduler.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "                \n",
    "                total_loss += loss.item() * self.config.accumulation_steps\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "                \n",
    "                # Periodic memory cleanup\n",
    "                if i % 50 == 0:\n",
    "                    gc.collect()\n",
    "                    if torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "        \n",
    "        return total_loss / len(self.train_loader)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        for batch in tqdm(self.val_loader, desc=\"Validating\"):\n",
    "            batch = {k: v.to(self.device) for k, v in batch.items()}\n",
    "            \n",
    "            outputs = self.model(**batch)\n",
    "            total_loss += outputs.loss.item()\n",
    "            \n",
    "            preds = torch.argmax(outputs.logits, dim=-1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch['labels'].cpu().numpy())\n",
    "        \n",
    "        metrics = {\n",
    "            'val_loss': total_loss / len(self.val_loader),\n",
    "            'accuracy': accuracy_score(all_labels, all_preds),\n",
    "            'f1': f1_score(all_labels, all_preds, average='weighted')\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def train(self):\n",
    "        for epoch in range(self.config.epochs):\n",
    "            logger.info(f\"Epoch {epoch + 1}/{self.config.epochs}\")\n",
    "            \n",
    "            # Training phase\n",
    "            train_loss = self.train_epoch()\n",
    "            \n",
    "            # Validation phase\n",
    "            val_metrics = self.validate()\n",
    "            \n",
    "            # Log metrics\n",
    "            metrics = {\n",
    "                'epoch': epoch + 1,\n",
    "                'train_loss': train_loss,\n",
    "                **val_metrics,\n",
    "                'learning_rate': self.scheduler.get_last_lr()[0]\n",
    "            }\n",
    "            wandb.log(metrics)\n",
    "            logger.info(f\"Metrics: {metrics}\")\n",
    "            \n",
    "            # Early stopping check\n",
    "            if val_metrics['val_loss'] < self.best_val_loss:\n",
    "                self.best_val_loss = val_metrics['val_loss']\n",
    "                self.save_checkpoint('best_model.pt', metrics)\n",
    "                self.patience_counter = 0\n",
    "            else:\n",
    "                self.patience_counter += 1\n",
    "                if self.patience_counter >= self.config.early_stopping_patience:\n",
    "                    logger.info(\"Early stopping triggered\")\n",
    "                    break\n",
    "    \n",
    "    def save_checkpoint(self, filename: str, metrics: Dict[str, Any]):\n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "            'metrics': metrics\n",
    "        }, filename)\n",
    "\n",
    "def create_small_config() -> BertConfig:\n",
    "    \"\"\"Creates a smaller BERT configuration for knowledge distillation\"\"\"\n",
    "    return BertConfig(\n",
    "        hidden_size=384,  # Half of BERT-base\n",
    "        num_hidden_layers=4,  # Third of BERT-base\n",
    "        num_attention_heads=6,\n",
    "        intermediate_size=1536,\n",
    "        hidden_dropout_prob=0.1,\n",
    "        attention_probs_dropout_prob=0.1,\n",
    "        num_labels=2\n",
    "    )\n",
    "\n",
    "def main():\n",
    "    # Initialize wandb\n",
    "    wandb.init(project=\"efficient-bert-compression\")\n",
    "    \n",
    "    # Configuration\n",
    "    config = TrainingConfig()\n",
    "    wandb.config.update(asdict(config))\n",
    "    \n",
    "    # Load and prepare datasets\n",
    "    logger.info(\"Loading datasets...\")\n",
    "    train_dataset = IMDBDataset('train', config)\n",
    "    val_dataset = IMDBDataset('test', config)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Train teacher model\n",
    "        logger.info(\"Training teacher model...\")\n",
    "        teacher_model = BertForSequenceClassification.from_pretrained(\n",
    "            'bert-base-uncased',\n",
    "            num_labels=2\n",
    "        )\n",
    "        \n",
    "        trainer = EfficientTrainer(\n",
    "            teacher_model,\n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            config\n",
    "        )\n",
    "        trainer.train()\n",
    "        \n",
    "        # Train smaller student model\n",
    "        logger.info(\"Training student model...\")\n",
    "        student_config = create_small_config()\n",
    "        student_model = BertForSequenceClassification(student_config)\n",
    "        \n",
    "        trainer = EfficientTrainer(\n",
    "            student_model,\n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            config\n",
    "        )\n",
    "        trainer.train()\n",
    "        \n",
    "        # Apply pruning to student model\n",
    "        logger.info(\"Applying pruning...\")\n",
    "        for name, module in student_model.named_modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                prune.l1_unstructured(module, name='weight', amount=0.3)\n",
    "        \n",
    "        # Fine-tune pruned model\n",
    "        trainer = EfficientTrainer(\n",
    "            student_model,\n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            config\n",
    "        )\n",
    "        trainer.train()\n",
    "        \n",
    "        # Quantization\n",
    "        logger.info(\"Quantizing model...\")\n",
    "        student_model.cpu()\n",
    "        quantized_model = torch.quantization.quantize_dynamic(\n",
    "            student_model,\n",
    "            {nn.Linear},\n",
    "            dtype=torch.qint8\n",
    "        )\n",
    "        \n",
    "        # Save final models\n",
    "        torch.save(student_model.state_dict(), 'compressed_model.pt')\n",
    "        torch.save(quantized_model.state_dict(), 'quantized_model.pt')\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        # Cleanup\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a212692-e187-46be-b83e-fcf823ee0f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HO\n"
     ]
    }
   ],
   "source": [
    "print(\"HO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63897459-e77d-46e2-9414-ff97db7393c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
